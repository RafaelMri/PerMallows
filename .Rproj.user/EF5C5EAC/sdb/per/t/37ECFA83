{
    "contents" : "//\n//  Hamming.cpp\n//  perms_mallows\n//\n//  Created by Ekhine Irurozki on 20/06/13.\n//  Copyright (c) 2013 Ekhine Irurozki. All rights reserved.\n//\n\n#include \"Hamming.h\"\n#include \"Generic.h\"\n#include \"Lap.h\"\n#include \"Newton_raphson.h\"\n\n#include <cmath>\n#include <float.h>\n#include <R.h>\n\ndouble Hamming::probability(int *s, int *s_0, double *theta){\n    double  pro = 0;\n    bool    MM = true ;\n    for (int i = 0 ; (i < n_ -1 && MM); i++) if ( theta[i] != theta[i+1]) MM = false;\n    if(MM){\n        int sum = 0;\n        for ( int i = 0 ; i < n_ ; i ++) if(s[i] != s_0[i]) sum ++;\n        return exp( -sum*theta[0] )/psi_hm(theta[0]);\n    }else{\n        for (int i = 0 ; i < n_ ; i++)\n            if (s[i] == s_0[i]) pro += 1;\n            else pro +=  theta[i] ;\n        return exp(-pro )/(double)psi_whm(theta);\n    }\n}\n\nint Hamming::distance(int*s1, int*s2){\n    int     sum = 0;\n    for ( int i = 0 ; i < n_ ; i ++) if(s1[i] != s2[ i ]) sum ++; //if(sigma[i] != i + 1) sum ++;\n    return sum;\n}\n\nvoid Hamming::random_derangement(int n, int *sigma){\n\n    if( n== 2) {\n        sigma[0]=2;\n        sigma[1]=1;\n    //}else if ( (n-1)*deran_num_[n-1] / deran_num_[n] > (double) rand() / RAND_MAX ){\n    }else if ( (n-1)*deran_num_[n-1] / deran_num_[n] > unif_rand() ){\n        random_derangement(n-1, sigma);\n        //int ran = rand() % (n - 1 );\n        int ran = (int) (unif_rand() * (n - 1 ));\n        sigma[n-1] = sigma[ran];\n        sigma[ran]= n;\n    }else{\n        int*deran = new int[ n - 2 ], *conv = new int[n-1];\n        random_derangement( n - 2 , deran );\n        //int ran = rand() % (n - 1 );\n        int ran = (int) (unif_rand() * (n - 1 ));\n        int j = 0;\n        for (int i= 0; i < n-1 ; i ++)\n            if ( i != ran ) conv[j++] = i+1;\n        j = 0;\n        for (int i = 0; i < n-1 ; i ++)\n            if (i != ran )\n                sigma[i] = conv[deran[j++]-1];\n        sigma[ran]= n ;\n        sigma[n-1] = ran+1;\n        delete [] deran;\n        delete [] conv;\n    }\n}\n\nvoid Hamming::random_sample_at_dist(int dist, int m, int **samples){\n    for (int i = 0 ; i < m ; i++) {\n        samples[i] = new int[n_];\n        random_permu_at_dist_d(dist, samples[i]);\n    }\n}\n\nvoid Hamming::random_permu_at_dist_d(int dist, int *sigma){\n    Generic gen;\n    int     *ran = new int[n_];\n    gen.generate_random_permutation(n_, 1, ran );\n    generate_permu_from_list(ran, dist, sigma);\n    delete [] ran;\n}\n\nint Hamming::perm2dist_decomp_vector(int*sigma, int*vec ){\n    int dist = 0 ;\n    for (int i = 0 ; i < n_ ;i++)\n        if (sigma[ i ] != i + 1 ){\n            dist ++;\n            vec[ i ] = 1;\n        }else\n            vec[ i ] = 0;\n    return dist;\n}\n\nvoid Hamming:: dist_decomp_vector2perm(int* vec, int* sigma){\n    int     *ran = new int[n_];\n    int     last = n_ - 1, first = 0;\n    for (int i = 0 ; i < n_; i++) {\n        if (vec[i] == 0 ) ran[ last-- ] = i + 1 ;\n        else ran[first ++] = i + 1;\n    }\n    //if ( first == 1 )bool traza = true;\n    generate_permu_from_list(ran, first, sigma);\n    //Generic gen;cout<< \"h \";gen.print_int_vector(h, n_); cout<< \"p \";gen.print_int_vector(permu, n_);\n    delete [] ran;\n}\n\nvoid Hamming::generate_permu_from_list(int*ran, int dist, int*sigma){\n    //the first d items in ran will be deranged. for the rest, sigma[i]=i\n    if ( dist == 0) {\n        for (int i = 0 ; i < n_ ; i++) sigma[i] = i + 1 ;\n        return;\n    }\n    int     *deran=new int[n_];\n    if(dist > 1) random_derangement(dist, deran);\n    for( int i = 0; i < dist; i++)\n        sigma[ ran[i] - 1 ] = ran  [ deran  [ i ] - 1 ];\n    for (int i = dist ; i < n_; i++)\n        sigma[ran[i] - 1 ]= ran[i];\n    delete [] deran;\n}\n\nvoid Hamming::distances_sampling(int m, double theta, int **samples){\n    // limit: n = 90\n    Generic     gen;\n    int         d_max = n_ ;\n    int         target_dist=0;\n    long double      rand_val;\n    long double      * fact       = new long double[ n_ + 1 ];\n    long double      * hamm_count = new long double[ n_ + 1 ];\n    long double      * acumul     = new long double[ d_max + 1];//+1\n    \n    fact[0]=1; fact[1]=1;\n    for ( int i = 2 ; i <= d_max ; i++) fact[i] = i * fact[i-1];\n    for ( int d = 0 ; d <= d_max ; d++) hamm_count[d] = (long double) deran_num_[d] *fact[n_] / (fact[d] * fact[n_ - d]) ;\n    acumul[ 0 ] = exp( -theta  * 0 ) * hamm_count[ 0 ];\n    for ( int dista = 1 ; dista <= d_max  ; dista++)\n        acumul[ dista ] = acumul[ dista - 1 ] +  (long double) exp(-theta  * dista) * hamm_count[ dista ];\n    \n    //gen.print_double_vector(hamm_count, n_+1);\n    //for (int d = 0 ; d <= d_max ; d++) cout<<acumul[d]<<\" \";cout<<endl;\n    for( int i = 0 ; i < m ; i++ ){\n        target_dist = 0;\n        //rand_val = (long double) acumul[ d_max ] * (double) rand() / RAND_MAX;\n        rand_val = (long double) (acumul[ d_max ] * unif_rand());\n        while ( acumul[ target_dist ] <= rand_val ) target_dist ++;\n        int *sigma = new int[ n_ ];\n        random_permu_at_dist_d( target_dist , sigma);\n        samples[ i ] = sigma;\n    }\n    delete [] fact;\n    delete [] acumul;\n    delete [] hamm_count;\n}\n\ndouble Hamming::psi_whm_reverse(double*theta){\n    long double res = 0 ;\n    Generic gen;\n    long double *esp = new long double [ n_ + 1 ];\n    double * theta_inv = new double [ n_ ];\n    for ( int k = 0 ; k < n_ ; k ++) theta_inv[ k ] = -theta[ k ];\n    gen.elementary_symmetric_polynomial( theta_inv, n_, t_, aux_esp_, esp );\n    //gen.init_factorials( n_ );\n    for ( int k = 0 ; k <= n_ ; k ++){\n        res += g_n_[ n_ ][k] * esp[k];//gen.count_permus_with_at_least_k_unfixed_points(n_,k)\n    }\n    delete [] esp;\n    delete [] theta_inv;\n    return res;\n}\n\ndouble Hamming::psi_whm(double*theta){\n    long double res = 0 , sum_theta = 0;\n    Generic gen;\n    long double *esp = new long double [ n_ + 1 ];\n    for ( int k = 0 ; k < n_ ; k ++) sum_theta += theta[ k ];\n    gen.elementary_symmetric_polynomial( theta, n_, t_, aux_esp_,esp );\n    for ( int k = 0 ; k <= n_ ; k ++){\n        res += facts_[ n_ - k ] * esp[k];\n    }\n    delete [] esp;\n    return (res * exp( -sum_theta ));\n}\n\ndouble Hamming::psi_hm_reverse(double theta){ // como el de fligner pero las epsilon son lo contrario\n    long double  sum = 0, aux;\n    Generic gen;\n    //gen.init_factorials( n_ );\n    for ( int i = 0 ; i <= n_ ; i ++ ){\n        //aux = (gen.count_permus_with_at_least_k_unfixed_points(n_,i) / (long double)(gen.get_factorial_in_table(n_-i)))/gen.get_factorial_in_table(i);\n        aux = (g_n_[ n_ ][ i ] / (facts_[ n_ - i ]))/facts_[ i ];\n        sum += (long double)aux*(long double)pow((exp(-theta)-1),i);\n    }\n    return (double)facts_[ n_ ] * sum;\n}\n\ndouble Hamming::psi_hm(double theta){ //fligner's\n    double  sum=0;\n    Generic gen;\n    for ( int i = 0 ; i <= n_ ; i ++ )\n        sum += ((double)pow((exp(theta)-1),i)/(double)gen.factorial(i));\n    sum = sum * exp( - n_ * theta) * gen.factorial( n_ );\n    return sum;\n}\n\n/*\nlong double Hamming::compute_marginal_slow(int *h , double * theta, int  marginal_order){\n    //|A| set of fixed points; |B| set of unfixed points\n    Generic gen;\n    int     a = 0 , b = 0 ;//a : |A|; b = |B|\n    long double  res = 0;\n    long double * esp_red_slow = new long double[ n_+1];\n     double * theta_red_slow = new  double[ n_+1];\n    double theta_acum_B = 0 , theta_acum_not_in_AB = 0;\n    for (int i = 0 ; i < marginal_order ; i++ ){\n        if ( h[ i ] == 1 ){\n            theta_acum_B += theta[ i ];\n            b++;\n        }\n    }\n    a = marginal_order - b ;\n    for (int i = marginal_order ; i < n_ ; i++ ){\n        theta_red_slow[ i - marginal_order ] = theta[ i ];\n        theta_acum_not_in_AB += theta[ i ];\n    }\n    gen.elementary_symmetric_polynomial( theta_red_slow, n_ - marginal_order ,t_, aux_esp_, esp_red_slow );\n//    for (int i = 0 ; i <= n_ - marginal_order ; i ++ )cout<<esp_red_slow[ i ]<<\" \"; cout<<\" slow\"<<endl;//cout<<\"a, b \"<<a<<\" \"<<b<<endl;\n    for (int k = 0 ; k <= n_ - marginal_order ; k++ )\n        res +=  gen.count_permus_with_at_least_k_unfixed_points(n_ -a -k, b) * (esp_red_slow[k] );\n    //cout<<\"res s \"<<res<<\" \"<<- theta_acum_not_in_AB - theta_acum_B<<endl;\n    //cout<<\" theta \"<<- theta_acum_not_in_AB - theta_acum_B<<endl;\n    return exp( - theta_acum_not_in_AB - theta_acum_B )* res;\n}**/\n\nlong double Hamming::compute_marginal_iterative(int *h , double * theta, int  marginal_order){\n    // must be initialized :\n    //esp_ini: elementary_symmetric_polynomial( theta, n_ ,..., esp_ini_ );\n    //t_sampling_[i]=exp(theta[i]-1\n    int     a = 0 ;//a : |A|; b = |B| is global\n    long double  result = 0;\n    int     current_var = marginal_order - 1;\n    int     num_vars = n_ - marginal_order;\n    long double  res = 0;\n    \n\n    if (marginal_order == 1 ){//the first time it is called\n        theta_acum_not_in_A = 0;\n        b_ = 0 ;\n        for (int i = 0 ; i < n_ ; i++ ){\n            theta_acum_not_in_A += theta[ i ];\n            esp_red_[ i ] = esp_ini_[ i ];\n        }\n        esp_red_[ n_ ] = esp_ini_[ n_ ];\n    }\n    if ( current_var > 0 ){\n        if( h[ current_var - 1 ] == 0 )\n            theta_acum_not_in_A -= theta[ current_var - 1];//the set of fixed points is A. If the last position was sampled as Unfix , update set\n        else\n            b_ ++;//otherwise, (current_var-1) \\in B\n    }\n    a = marginal_order - b_; // ojo: h[current var] = 0 => current_var \\in A\n    //split the ESP by variable current_var:\n    //esp -> esp_no_a + esp_yes_a\n    //since esp in the next iteration we be esp_no_a of the current iter (esp=esp_no_a) then\n    //esp_no_a is directly stored in esp\n    esp_red_yes_a_[1]= t_sampling_[ current_var ];\n    for (int k = 1 ; k < num_vars ; k ++){\n        esp_red_[k]= esp_red_[k] - esp_red_yes_a_[k];\n        esp_red_yes_a_[ k + 1 ] =  esp_red_[k]* t_sampling_[ current_var ];\n        res +=  g_n_[ n_ -a -k ][ b_ ] * esp_red_[k];\n    }\n    esp_red_[num_vars]= esp_red_[num_vars] - esp_red_yes_a_[num_vars];\n    res +=  g_n_[n_ - a ][ b_ ] ;//* esp_red_[0]; // iter k=0\n    if (num_vars != 0)\n        res +=  g_n_[n_ -a - num_vars][ b_ ] * esp_red_[num_vars]; // iter k= num_vars\n    \n    result = (long double) exp( - theta_acum_not_in_A + theta[ current_var ] )* res;\n    /*if ( result < 0 ){\n        cout<<\"Negative marginal probability, maybe theta is too large?\"<<endl;\n        exit(0);\n    }*/\n    return result;\n}\n\nlong double Hamming::compute_marginal(int *h , double * theta ){\n    Generic gen;\n    double  * theta_red = new double[ n_ ];\n    double  theta_not_in_a = 0;\n    int     a = 0 , b = 0 , num_vars = 0;\n    long double res =  0, psi = 0 ;\n\n    for (int i = 0 ; i < n_ ; i++ ){\n        if( h[ i ] == 0) a++;\n        else theta_not_in_a += theta[ i ];\n        if( h[ i ] == 1 ) b++;        \n        if( h[ i ] != 1 &&  h[ i ] != 0 ) {\n            theta_red[ num_vars ++ ] = theta[ i ];\n        }\n    }\n    psi = psi_whm(theta);\n    gen.elementary_symmetric_polynomial( theta_red, num_vars , t_, aux_esp_, esp_red_ );\n    for (int k = 0 ; k < num_vars + 1 ; k ++)\n        res +=  g_n_[ n_ -a -k ][ b ] * esp_red_[k];\n    \n    delete [] theta_red;\n    return (long double) exp( - theta_not_in_a  )* res / psi;\n}\n\n\nvoid Hamming::multistage_sampling(int m, double *theta, int **samples){\n    Generic gen;\n    int     *h = new int[ n_ ]; for ( int i = 0 ; i < n_ ; i ++ ) h[ i ] = 0;\n    long double  marg = 0, marg_0 = 0, marg_1 = 0, rand_double = 0 ;\n    long double  marg_ini = 0;\n    \n    for ( int i = 0 ; i < n_ ; i ++ ) t_sampling_[ i ] = (long double) exp( theta[ i ]) - 1 ;\n\n    marg_ini = psi_whm(theta);\n    \n    //initialize esp_ini_;\n    gen.elementary_symmetric_polynomial( theta, n_ ,t_, aux_esp_, esp_ini_ );\n    for (int s = 0 ; s < m ; s ++) {\n        marg = marg_ini;\n        for (int items_set = 0 ; items_set < n_; items_set++) {\n            h[ items_set ] = 0; //for the marginal computation\n            marg_0 = rand_double = 0;\n            marg_0 = compute_marginal_iterative(h , theta, items_set + 1);//8\n            marg_1 = marg - marg_0;\n            //rand_double = marg * (double)rand() / (RAND_MAX);//2\n            rand_double = marg * unif_rand();\n            if (rand_double < marg_0) {\n                marg = marg_0;\n                h[ items_set ] = 0;\n            }else{\n                marg = marg_1;\n                h[ items_set ] = 1;\n            }\n        }\n        samples[ s ] = new int[ n_ ];\n        dist_decomp_vector2perm(h , samples[ s ]);\n    }\n    delete [] h;\n \n}\n\nvoid Hamming::gibbs_sampling(int m, double *theta, int model, int **samples){\n    int burning_period_samples = n_*n_;\n    int*sigma = new int[ n_ ];\n    Generic  gen;\n    gen.generate_random_permutation( n_ , 1, sigma);\n    double ratio = 0 , rand_double = 0 ;\n    int h_i = 0, h_j = 0, h_i_new = 0, h_j_new = 0;\n    \n    for ( int sample = 0 ; sample < m + burning_period_samples ; sample ++){\n        int i, j;\n        do{\n            //i = rand() % (n_);\n            //j = rand() % (n_);\n            i = (int) (unif_rand() * n_);\n            j = (int) (unif_rand() * n_);\n        }while ( i == j );\n        h_i     = (i == sigma[i] - 1) ? 0 : 1 ;\n        h_j     = (j == sigma[j] - 1) ? 0 : 1 ;\n        h_i_new = (i == sigma[j] - 1) ? 0 : 1 ;\n        h_j_new = (j == sigma[i] - 1) ? 0 : 1 ;\n        \n        ratio = exp(- h_j_new * theta[j]) * exp(- h_i_new * theta[i]) / (exp(- h_j * theta[j]) * exp(- h_i * theta[i]));\n        //rand_double = (double)rand()/RAND_MAX;\n        rand_double = unif_rand();\n        if (rand_double < ratio ) {\n            int aux = sigma[i];\n            sigma[i] = sigma[j];\n            sigma[j] = aux;\n        }\n        if(sample>=burning_period_samples){\n            samples[sample-burning_period_samples]=new int[ n_ ];\n            for ( int i = 0  ; i < n_ ; i ++)   samples[ sample - burning_period_samples ][ i ] = sigma[ i ];\n        }\n    }\n    delete [] sigma;\n}\n\nint Hamming::distance_to_sample(int **samples, int m, int *sigma){\n    int dist= 0;\n    //int *comp = new int[ n_ ], *sigma_inv = new int[ n_ ];\n    //for(int j = 0 ; j < n_ ; j ++) sigma_inv[sigma[ j ] - 1 ] = j + 1;\n    for(int s = 0 ; s < m ; s ++){\n        //for(int i = 0 ; i < n_ ; i ++) comp[ i ] = samples[ s ][ sigma_inv [ i ] - 1 ];\n        for ( int i = 0 ; i < n_ ; i ++) if(samples[ s ][ i ] != sigma[ i ]) dist ++; //if(sigma[i] != i + 1) sum ++;\n        //dist += distance(comp);\n    }\n    //delete []sigma_inv;\n    //delete []comp;\n    return dist;\n}\n\nvoid Hamming::estimate_consensus_exact_mm(int m, int**samples, int*sigma){\n    int**freq = new int*[n_];\n    Lap lap;\n    int*rows=new int[n_], *cols=new int[n_], *u=new int[n_], *v=new int[n_];\n    for (int i = 0 ; i < n_ ; i++ ){freq[i]=new int[n_]; for (int j = 0 ; j < n_ ; j++)freq[i][j] = 0 ;}\n    \n    for (int i = 0 ; i < m ; i ++)\n        for (int j = 0 ; j < n_ ; j ++)\n            freq[j][samples[i][j]-1]--;\n    \n    //int cost = -1 * lap.lap(n_, freq, rows, cols, u, v);\n    lap.lap(n_, freq, rows, cols, u, v);\n    for (int i = 0; i < n_; i++)\n        sigma[i] = rows[i] + 1;\n    delete [] rows;\n    delete [] cols;\n    delete [] u;\n    delete [] v;\n    for (int i = 0 ; i < n_ ; i++) delete [] freq[ i ];\n    delete [] freq;\n}\n\n/*double Hamming::estimate_consensus_exact_gmm_core(int m, int **freq ,int * max_index_in_col, double * h_avg, int *sigma_0, int*sigma_0_inv, int pos, double previous_likelihood, double *best_likelihood, int *best_sigma_0){\n    Generic gen;\n    //TODO mejorar la cota pal resto\n    long double nodes = 1;\n    if ( pos == n_ && ( *best_likelihood < previous_likelihood || *best_likelihood == 0) ) {\n        cout<<\"leafBEST: lik, bestL \"<<previous_likelihood<<\" \"<<*best_likelihood<<endl;\n        *best_likelihood = previous_likelihood;\n        for (int i = 0 ; i < n_ ; i++) best_sigma_0[ i ] = sigma_0[ i ];\n        //for (int i = 0 ; i < n_ ; i++) cout<< sigma_0_inv[ i ]<<\" \";cout<<\"sigma_o\"<<endl;\n\n    }else{\n        Newton_raphson nr(n_);\n        long double  likelihood, a1;\n        int     * max_index_in_col_bounded = new int[ n_ ];\n        double  * theta = new double[ n_ ];\n        double  * h_avg_bounded = new double [n_ ];\n        for (int item = 0 ; item < n_ ; item ++){\n            if (sigma_0[ item ] == -1 ) {//\n                sigma_0_inv[ pos ] = item + FIRST_ITEM;\n                sigma_0[ item ] = pos + FIRST_ITEM;\n                if(sigma_0[0]==2&&sigma_0[1]==1&&sigma_0[2]==3&&sigma_0[3]==4){\n                    bool traza = true;\n                }\n                bound_consensus (m, pos, freq, sigma_0, sigma_0_inv, h_avg, max_index_in_col, h_avg_bounded, max_index_in_col_bounded);\n                nr.mle_theta_weighted_mallows_hamming( m , h_avg_bounded, theta);\n                a1 = 0 ;\n                for ( int i = 0 ; i < n_ ; i++) a1 += h_avg_bounded[ i ] * theta[ i ] ;\n                likelihood = (long double)-m * (a1 + (long double)log (psi_whm(theta)));\n                if ((previous_likelihood < likelihood) && abs(previous_likelihood - likelihood)>0.0001 && previous_likelihood != 0 ){\n                    cout<<\"ERROR likeli must decrease down tree \"<<pos<<\" \"<<previous_likelihood<<\" \"<<likelihood<<\" \"<<previous_likelihood - likelihood<<\" \"<<*best_likelihood<<endl;\n                }\n     //           if (likelihood >= *best_likelihood || *best_likelihood == 0 ){\n                cout<<\"  \";gen.print_int_vector(sigma_0_inv, n_);cout<<\"\\t\\t\"<<likelihood<<\"\\n\";\n                cout<<\"\\t\\t\";gen.print_double_vector(h_avg_bounded, n_);\n                cout<<\"\\t\\t\";gen.print_double_vector(theta, n_);\n                 \n                    nodes += estimate_consensus_exact_gmm_core(m, freq, max_index_in_col_bounded, h_avg_bounded,sigma_0, sigma_0_inv, pos + 1,likelihood, best_likelihood, best_sigma_0);\n       //         }else {\n                  //  cout<<\"x \";gen.print_int_vector(sigma_0_inv, n_);cout<<\"\\t\\t\"<<likelihood<<\"\\n\";\n                  //  cout<<\"\\t\\t\";gen.print_double_vector(h_avg, n_);\n       //         }\n                sigma_0_inv[ pos ] = -1;\n                sigma_0[ item ] = -1;\n                //h_avg[ pos ] = h_min[ pos ];\n            }\n        }\n        delete [] h_avg_bounded;\n        delete [] theta;\n        delete [] max_index_in_col_bounded;\n    }\n    return nodes;\n}\n\nvoid Hamming::bound_consensus(int m, int pos, int **freq, int *sigma_0, int *sigma_0_inv, double *h_avg, int *max_index_in_col, double *h_avg_bounded, int *max_index_in_col_bounded){\n    for (int i = 0 ; i < pos ; i++) {\n        h_avg_bounded [ i ] =  h_avg[ i ];\n        max_index_in_col_bounded[ i ] = 0;\n    }\n    h_avg_bounded[ pos ] = (double) 1 - (double) freq[ sigma_0_inv[ pos ] - FIRST_ITEM ][ pos ] / m;\n    for (int col = pos+1 ; col < n_ ; col++) {//h_avg_bounded [ i ] =  h_avg[ i ];\n        if (max_index_in_col[ col ] != sigma_0_inv[ pos ]) \n            max_index_in_col_bounded[ col ] = max_index_in_col[ col ];\n         else{\n                max_index_in_col_bounded[ col ] = -1;\n                for (int row = 0 ; row < n_ ; row++ ){\n                    if ( sigma_0[ row ] == -1 && ( max_index_in_col_bounded[ col ] == -1 || freq[ row ][ col ] > freq[max_index_in_col_bounded[ col ]][ col ] ))\n                        max_index_in_col_bounded[ col ] = row;\n                }\n            }\n        h_avg_bounded[ col ] = (double) 1 - (double) freq[ max_index_in_col[ col ] ] [ col ]/ m;\n        \n    }\n    for (int i = 0 ; i < n_ ; i++)\n        if (h_avg_bounded[ i ] < h_avg[ i ]){//trace\n            cout<<\"ERROR: h_avg must increase down tree\"<<endl;\n            Generic gen;\n            gen.print_int_vector(sigma_0, n_);\n            gen.print_int_vector(sigma_0_inv, n_);\n            gen.print_double_vector(h_avg, n_);\n            gen.print_double_vector(h_avg_bounded , n_);\n            gen.print_int_vector(max_index_in_col, n_);\n            gen.print_int_vector(max_index_in_col_bounded, n_);\n        }\n}\n\ndouble Hamming::estimate_consensus_exact_gmm(int m, int **samples, int*sigma_0_ini, int *sigma_0){\n    //return num_nodes\n    Generic gen;\n    int     ** freq             = new int * [ n_ ];\n    int     *  max_index_in_col = new int [ n_ ];\n    int     *  sigma_0_inv      = new int[ n_ ];\n    int     *  sigma_0_iter     = new int[ n_ ];\n    double  *  h_avg            = new double[ n_ ];\n    double  likelihood = 0 ;\n    for (int i = 0 ; i < n_ ; i++) {\n        sigma_0[ i ] = sigma_0_inv[ i ] = sigma_0_iter[ i ] = -1;\n        max_index_in_col[ i ] = -1 ;\n        freq[ i ] = new int [ n_ ]; for (int j = 0 ; j < n_ ; j ++) freq[ i ][ j ] = 0 ;\n    }\n    \n    for (int s = 0 ; s < m ; s ++)\n        for (int j = 0 ; j < n_ ; j ++)\n            freq[ j ][ samples[ s ][ j ] - 1 ]++;\n    //gen.print_int_matrix(freq, n_, n_);\n    for (int j = 0 ; j < n_ ; j++)\n        for (int i = 0 ; i < n_ ; i ++)\n            if (  max_index_in_col[ j ] == -1 || freq[ i ][ j ] > freq[  max_index_in_col[ j ] ][ j ]  )\n                max_index_in_col[ j ] = i;\n    for (int j = 0 ; j < n_ ; j++){\n        h_avg[ j ] = (double ) 1.0 - (double) freq[ max_index_in_col[ j ]][ j ] / m;\n    }\n    \n    //obtain the likelihod of the approx solution\n    estimate_consensus_approx_gmm(m, samples, sigma_0, &likelihood);\n\n    if ( sigma_0_ini != NULL ){\n        //obtain the likelihod of the proposed sigma_0_ini.\n        double like_ini = get_likelihood(m , samples , GENERALIZED_MALLOWS_MODEL , sigma_0_ini);\n        //check both solutions: the proposed sigma_0_ini vs. the approx. Discard the worse\n        if (like_ini > likelihood) {\n            likelihood = like_ini;\n            for (int i = 0 ; i < n_ ; i++) sigma_0[ i ] = sigma_0_ini[ i ];\n        }\n    }\n    \n    double nodes = estimate_consensus_exact_gmm_core(m, freq, max_index_in_col, h_avg, sigma_0_iter, sigma_0_inv, 0,0, &likelihood, sigma_0);\n    //cout<<\"num_nodes \"<<nodes<<endl;\n    \n    for (int i = 0 ; i < n_ ; i++) delete [] freq[ i ];\n    delete [] freq;\n    delete [] max_index_in_col;\n    delete [] sigma_0_inv;\n    delete [] sigma_0_iter;\n    delete [] h_avg;\n    return nodes;\n}*/\n\ndouble Hamming::expectation(double theta){\n    double x_n = 0 , x_n_1 = 0, aux = 0 ;\n    for (int k = 0 ; k <= n_ ; k ++){\n        aux = pow (exp(theta )-1, k) / facts_[ k ];\n        x_n += aux;\n        if (k < n_ )\n            x_n_1 += aux ;//pow (exp(theta )-1, k) / facts_[ k ];\n    }\n    return (double )(n_ * x_n - x_n_1 * exp( theta )) / x_n;\n}\n\nvoid Hamming::expectation(double *theta, double*h_expected){\n    double numer = 0 , denom = 0 ;\n    long double ** esp_no_a_  = new long double*[ n_ + 1 ];\n    long double ** esp_yes_a_ = new long double*[ n_ + 1 ];\n    for (int k = 0 ; k <= n_ ; k ++){\n        esp_no_a_ [ k ]= new long double [ n_ ];\n        esp_yes_a_[ k ]= new long double [ n_ ];\n        for (int i = 0 ; i < n_ ; i ++){\n            esp_no_a_ [ k ][ i ] = 0;\n            esp_yes_a_[ k ][ i ] = 0;\n        }\n    }\n    Generic gen;\n    gen.elementary_symmetric_polynomial(theta, n_, t_, aux_esp_,esp_red_ );\n    gen.split_elementary_symmetric_polynomial (esp_red_, theta , n_, esp_no_a_, esp_yes_a_);\n\n    for ( int i = 0 ; i < n_ ; i++ ){\n        numer = denom = 0 ;\n        for (int k = 0 ; k <= n_ ; k ++){\n            if (k > 0 )numer += facts_[n_ - k ]  * esp_no_a_[ k - 1 ][ i ];\n            denom += facts_[n_ - k ] * esp_red_[ k ];\n        }\n        h_expected[ i ] = 1 - (numer * exp( theta[ i ])) / denom ;\n    }\n    for (int k = 0 ; k <= n_ ; k ++){\n        delete [] esp_no_a_ [ k ];\n        delete [] esp_yes_a_[ k ];\n    }\n    delete [] esp_no_a_;\n    delete [] esp_yes_a_;\n}\n\nvoid Hamming::sample_to_h_vector(int **samples, int m, int * sigma, double *h_avg){\n    //if sigma != NULL => h( samples sigma^{-1} )\n    for (int i = 0 ; i < n_ ; i++) h_avg[ i ] = 0;\n    for (int s = 0 ; s < m ; s ++)\n        for (int i = 0 ; i < n_ ; i++)\n            if ( sigma == NULL ){\n                if (samples[s][ i ] != i + 1)\n                    h_avg[ i ] ++;\n            }else {//right compose with the inverse of the sample\n                //h_j = 0  <=> sigma^{-1}(j) = sigma_0^{-1}(j) <=> sigma(i) = sigma_0(i) = j\n                if ( sigma[ i ] != samples[ s ][ i ])\n                    h_avg[ samples[ s ][ i ] - 1] ++;\n            }\n    for (int i = 0 ; i < n_ ; i++) h_avg[ i ] = (double) h_avg[ i ] / m ;\n}\n\nvoid Hamming::estimate_consensus_approx_gmm(int m, int **samples, int *sigma_0, double * best_likelihood){\n    Lap     lap;\n    Newton_raphson nr(n_);\n    Generic gen;\n    int     * sigma_0_inv = new int[ n_ ],* sigma_0_inv_neig_best = new int[ n_ ];\n    int     ** freq = new int*[ n_ ];\n    int     * rows=new int[n_], *cols=new int[n_], *u=new int[n_], *v=new int[n_];\n    double  * h_avg = new double[ n_ ],*theta= new double[ n_ ];\n    double  a1 = 0;\n    for (int i = 0 ; i < n_ ; i++){ freq[ i ]= new int[n_ ]; for(int j = 0 ; j < n_ ;  j++) freq[ i ][ j ] = 0 ;}\n    \n    for (int i = 0 ; i < m ; i ++)\n        for (int j = 0 ; j < n_ ; j ++)\n            freq[ j ][ samples[ i ][ j ] - FIRST_ITEM ]--;//for the lap, minimize\n    \n    //int cost = -1 * lap.lap(n_, freq, rows, cols, u, v);\n    lap.lap(n_, freq, rows, cols, u, v);\n    for (int i = 0 ; i < n_ ; i++){\n        sigma_0[ i ] = rows[i] + FIRST_ITEM;\n        sigma_0_inv[ (rows[i] + FIRST_ITEM )- FIRST_ITEM] = i + FIRST_ITEM;\n    }\n    \n    for (int i = 0 ; i < n_ ; i++)\n        for(int j = 0 ; j < n_ ;  j++)\n            freq[ i ][ j ] = freq[ i ][ j ] * -1;\n    for (int i = 0 ; i < n_ ; i++){\n        //h_vec[ i ] = m - freq[ sigma_0_inv[ i ]][ i ];\n        h_avg[ i ] = (double ) 1 - (double)freq[ sigma_0_inv[ i ] - FIRST_ITEM ][ i ] / m ;\n    }\n    nr.mle_theta_weighted_mallows_hamming( m , h_avg, theta);\n    for ( int i = 0 ; i < n_ ; i++) a1 += h_avg[ i ] * theta[ i ] ;\n    *best_likelihood = (double)-m * (a1 + log ( psi_whm(theta)));\n    //variable_neighborhood_search(m , freq , sigma_0_inv , best_likelihood);\n    //for(int i = 0 ; i < n_; i ++) sigma_0[ sigma_0_inv[ i ] - FIRST_ITEM ] = i + FIRST_ITEM;\n    \n    for (int i = 0 ; i < n_ ; i++) delete [] freq[ i ];\n    delete [] theta;\n    delete [] rows;\n    delete [] h_avg;\n    delete [] cols;\n    delete [] u;\n    delete [] v;\n    delete [] freq;\n    delete [] sigma_0_inv_neig_best;\n    delete [] sigma_0_inv;\n}\n\nvoid Hamming::variable_neighborhood_search(int m, int **freq, int *sigma_0_inv, double *f_eval){\n    double f_eval_ini;\n    Generic gen;\n    do{\n        f_eval_ini = (*f_eval);\n       // cout<<\" distance ini\"<<(*f_eval)<<\"\\t \"; gen.print_int_vector(sigma_0_inv, n_);\n        local_search_swap_gmm  (m, freq, sigma_0_inv, f_eval);\n       // cout<<\" distance new swap \"<<(*f_eval)<<\"\\t \"; gen.print_int_vector(sigma_0_inv, n_);\n        local_search_insert_gmm(m, freq, sigma_0_inv, f_eval);\n       // cout<<\" distance new ins \"<<(*f_eval)<<\"\\t \"; gen.print_int_vector(sigma_0_inv, n_);\n    }while( (f_eval_ini) < *f_eval );//(improve);\n//    cout<<\"end vns\"<<endl;\n}\n\nvoid Hamming::local_search_insert_gmm(int m, int **freq, int *sigma_0_inv, double *f_eval){\n    Newton_raphson nr(n_);\n    Generic gen;\n    int     * sigma_0_inv_neig_best = new int[ n_ ];\n    int     * next_sol_inv      = new int[ n_ ];\n    double  * theta             = new double[ n_ ];\n    double  * h_avg              = new double [ n_ ];\n    double  a1 = 0 ;\n    double  likelihood_neig  =0, likelihood_neig_best=0;\n    bool halt_local_search;\n    do {\n        likelihood_neig_best = 0;\n        halt_local_search = true;\n\n        for(int from = 0 ; from < n_ ; from ++){\n            for ( int to = 0 ; to < n_ ; to++){\n                if(from != to){\n                    gen.insert_at (sigma_0_inv, n_, from, to, next_sol_inv);\n                    for (int i = 0 ; i < n_ ; i++)\n                    {h_avg[ i ] = (double ) 1 - (double)freq[ next_sol_inv[ i ] - FIRST_ITEM ][ i ] / m ;\n                    }\n                    nr.mle_theta_weighted_mallows_hamming( m , h_avg, theta);\n                    a1 = 0;\n                    for ( int i = 0 ; i < n_ ; i++) a1 += h_avg[ i ] * theta[ i ] ;\n                    likelihood_neig = (double)-m * (a1 + log ( psi_whm(theta)));\n                    if (likelihood_neig > likelihood_neig_best || likelihood_neig_best == 0){\n                        likelihood_neig_best = likelihood_neig;\n                        for ( int i = 0 ; i < n_ ; i++) sigma_0_inv_neig_best [ i ] = next_sol_inv[ i ];\n                    }\n                    \n                }\n            }\n        }\n        \n        if( likelihood_neig_best > *f_eval){\n            *f_eval = likelihood_neig_best;\n            for (int i = 0 ; i < n_ ; i ++) sigma_0_inv [ i ] = sigma_0_inv_neig_best[ i ];\n            halt_local_search = false;\n        }\n    } while ( ! halt_local_search);\n    delete [] h_avg;\n    delete [] sigma_0_inv_neig_best;\n    delete [] theta;\n    delete [] next_sol_inv;\n}\n\nvoid Hamming::local_search_swap_gmm(int m, int **freq, int *sigma_0_inv, double *f_eval){\n    int     * sigma_0_inv_neig_best = new int[ n_ ];\n    int     *rows=new int[n_], *cols=new int[n_], *u=new int[n_], *v=new int[n_];\n    double  *theta = new double [ n_ ];\n    double   * h_avg = new double[ n_ ];\n    double   likelihood_neig_best, likelihood_neig, a1 = 0;\n\n    Newton_raphson nr(n_);\n    Generic gen;\n\n    for (int i = 0 ; i < n_ ; i++){\n        //h_vec[ i ] = m - freq[ sigma_0_inv[ i ]][ i ];\n        h_avg[ i ] = (double ) 1 - (double)freq[ sigma_0_inv[ i ] - FIRST_ITEM ][ i ] / m ;\n    }\n    \n    bool halt_local_search;\n    do{\n        halt_local_search = true;\n        likelihood_neig_best = 0;\n        for (int i = 0 ; i < n_ - 1; i++)\n            for (int j = i+1 ; j < n_ ; j++){\n                    int aux = sigma_0_inv[ i ];\n                    sigma_0_inv [ i ] = sigma_0_inv[ j ];\n                    sigma_0_inv[ j ] = aux;\n                    h_avg[ i ] = (double) 1 - (double) freq[ sigma_0_inv[ i ] - FIRST_ITEM ][ i ] / m;\n                    h_avg[ j ] = (double) 1 - (double) freq[ sigma_0_inv[ j ] - FIRST_ITEM ][ j ] / m;\n\n                    nr.mle_theta_weighted_mallows_hamming( m , h_avg, theta);\n                    a1 = 0;\n                    for ( int r = 0 ; r < n_ ; r++) a1 += h_avg[ r ] * theta[ r ] ;\n                    likelihood_neig = (double) -m * (a1 + log ( psi_whm(theta)));\n                    if (likelihood_neig > likelihood_neig_best || likelihood_neig_best == 0){\n                        likelihood_neig_best = likelihood_neig;\n                        for ( int i = 0 ; i < n_ ; i++) sigma_0_inv_neig_best [ i ] = sigma_0_inv[ i ];\n                    }\n                    \n                    aux = sigma_0_inv[ i ];\n                    sigma_0_inv [ i ] = sigma_0_inv[ j ];\n                    sigma_0_inv[ j ] = aux;\n                    h_avg[ i ] = (double) 1 - (double) freq[ sigma_0_inv[ i ] - FIRST_ITEM ][ i ] / m;\n                    h_avg[ j ] = (double) 1 - (double) freq[ sigma_0_inv[ j ] - FIRST_ITEM ][ j ] / m;\n                    \n                }\n        if ( *f_eval < likelihood_neig_best ){\n            //cout<<\"better sol found in swap \"<<likelihood_neig_best<<endl;\n            halt_local_search = false;\n            *f_eval = likelihood_neig_best;\n            for ( int i = 0 ; i < n_ ; i++) sigma_0_inv[ i ] = sigma_0_inv_neig_best[ i ];\n        }\n    }while ( ! halt_local_search) ;\n    //for (int i = 0 ; i < n_ ; i++) sigma_0[ sigma_0_inv[ i ] - FIRST_ITEM ] = i + FIRST_ITEM;\n\n    delete [] theta;\n    delete [] rows;\n    delete [] h_avg;\n    delete [] cols;\n    delete [] u;\n    delete [] v;\n    delete [] sigma_0_inv_neig_best;\n}\n\n\nlong double Hamming::get_likelihood(int m, int **samples, int model, int * sigma_0){\n    Newton_raphson nr(n_);\n    long double likelihood ;\n    double  * theta = new double[ n_ ];\n    double  psi, a1 = 0;\n    if(model == MALLOWS_MODEL){\n        int dist = distance_to_sample(samples, m, sigma_0);\n        theta[ 0 ] = nr.Newton_raphson_method( (double) dist/m, 0.0, HAMMING_DISTANCE, MALLOWS_MODEL, NULL, NULL);\n        psi = psi_hm(theta[ 0 ]);\n        likelihood =  - theta[0] * dist - m * log( psi );\n    }else{\n        Generic gen;\n        double  * h_avg = new double[ n_];\n        sample_to_h_vector(samples, m, sigma_0, h_avg);\n        nr.mle_theta_weighted_mallows_hamming( m , h_avg, theta);\n        for ( int i = 0 ; i < n_ ; i++) a1 +=(double)h_avg[i]  * theta[ i ] ;\n        delete [] h_avg;\n        likelihood = (long double)-m * (a1 + log ( psi_whm(theta)));\n    }\n    delete [] theta;\n    return likelihood;\n}\n\nlong double Hamming::get_likelihood_from_h(int m, int model, double *theta, double * h_avg){\n    long double likelihood ;\n    double psi, a1 = 0;\n    if(model == MALLOWS_MODEL){\n        int dist = 0;\n        for (int i = 0 ; i < n_ ;i ++) dist += h_avg[ i ];\n        dist *= m;\n        psi = psi_hm(theta[ 0 ]);\n        likelihood =  - theta[0] * dist - m * log( psi );\n    }else{\n        Generic gen;\n        int   *h_sum = new int[ n_];\n        for ( int i = 0 ; i < n_ ; i++) h_sum[ i ] = h_avg[ i ]* m;\n        for ( int i = 0 ; i < n_ ; i++) a1 +=(double)h_sum[i] / m * theta[ i ] ;\n        delete [] h_sum;\n        likelihood = (long double)-m * (a1 + log ( psi_whm(theta)));\n    }\n    return likelihood;\n}\n\n\nvoid Hamming::estimate_theta(int m, int *sigma_0, int **samples, int model, double *theta){\n    Newton_raphson nr(n_);\n    if (model == MALLOWS_MODEL){\n        //Newton_raphson nr(n_);\n        double  dist = 0;\n        dist = distance_to_sample( samples, m, sigma_0);\n        *theta = nr.Newton_raphson_method( (double) dist/m, 0.0, HAMMING_DISTANCE, MALLOWS_MODEL, NULL, NULL);\n    }\n    else{\n        Generic gen;\n        double   *h_avg         = new double [ n_ ];\n        sample_to_h_vector(samples, m, sigma_0, h_avg);\n        nr.mle_theta_weighted_mallows_hamming( m , h_avg, theta);\n        //for ( int j = 0 ; j < n_ ; j ++) cout<< theta[j]<<\" \"; cout<<\" theta (estimate_theta_gmm) \"<<endl;\n        \n        delete [] h_avg;\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1410609972021.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2096974458",
    "id" : "37ECFA83",
    "lastKnownWriteTime" : 1410607120,
    "path" : "~/Dropbox/permus/prj/R/PerMallows/src/Hamming.cpp",
    "project_path" : "src/Hamming.cpp",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "cpp"
}